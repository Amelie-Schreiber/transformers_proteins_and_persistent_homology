{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motif and Substructure Discovery with ESM-2 and Persistent Homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing necessary libraries\n",
    "from transformers import EsmModel, AutoTokenizer\n",
    "import gudhi as gd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import pdist, jensenshannon, squareform\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from gudhi.hera import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"MAVESRVTQEEIKKEPEKPIDREKTCPLLLRVFTTNNGRHHRMDEFSRGNVPSSELQIYTWMDATLKELTSLVKEVYPEARKKGTHFNFAIVFTDVKRPGYRVKEIGSTMSGRKGTDDSMTLQSQKFQIGDYLDIAITPPNRAPPPSGRMRPY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "def compute_output(sentence, layer, head):\n",
    "    # Load pre-trained model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "    model = EsmModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_attentions=True)\n",
    "\n",
    "    # Tokenize input and convert to tensor\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    # Forward pass\n",
    "    # Specify `output_hidden_states=True` when calling the model\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    # Obtain the attention weights\n",
    "    attentions = outputs.attentions\n",
    "\n",
    "    # Obtain the attention weights for the specific layer and head\n",
    "    S = attentions[layer][0, head]\n",
    "\n",
    "    # Obtain the value vectors\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden_states = outputs.hidden_states[layer]\n",
    "        all_W_v = model.encoder.layer[layer].attention.self.value.weight\n",
    "        num_heads = model.config.num_attention_heads\n",
    "        head_dim = model.config.hidden_size // num_heads\n",
    "        W_v_heads = all_W_v.view(num_heads, head_dim, model.config.hidden_size)\n",
    "        W_v = W_v_heads[head]\n",
    "        V = torch.matmul(hidden_states, W_v.t())\n",
    "\n",
    "    # Compute the output O\n",
    "    O = torch.matmul(S, V)\n",
    "\n",
    "    return O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 155, 16])\n",
      "tensor([[[ 0.6743,  0.5545,  1.2208,  ...,  0.0626, -0.9014, -0.7621],\n",
      "         [ 0.6362,  0.4581,  1.1848,  ...,  0.0766, -0.9643, -0.7803],\n",
      "         [ 0.6222,  0.4346,  1.1726,  ...,  0.0467, -0.9650, -0.7802],\n",
      "         ...,\n",
      "         [ 0.7480,  0.3212,  0.9947,  ..., -0.2329, -0.6257, -0.7537],\n",
      "         [ 0.7485,  0.3842,  1.0374,  ..., -0.2265, -0.6053, -0.7752],\n",
      "         [ 0.6429,  0.5328,  1.0885,  ..., -0.3019, -0.6538, -0.7992]]],\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Set the layer and head to use for computation\n",
    "layer = 3\n",
    "head = 2\n",
    "\n",
    "# Compute the context vectors for each text in the corpus\n",
    "context = [compute_output(t, layer, head) for t in text]\n",
    "print(context[0].shape)\n",
    "print(context[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barcode for text 0:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import distance_matrix\n",
    "import gudhi as gd\n",
    "\n",
    "def compute_distances_and_plot_barcode(output):\n",
    "    # Detach the output tensor, squeeze, and convert to numpy array\n",
    "    output_np = output.squeeze().detach().numpy()\n",
    "\n",
    "    # Compute the pairwise Euclidean distance matrix\n",
    "    distances = distance_matrix(output_np, output_np)\n",
    "\n",
    "    # Compute the persistent homology of the distance matrix\n",
    "    rips_complex = gd.RipsComplex(distance_matrix=distances, max_edge_length=np.max(distances))\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "    persistent_homology = simplex_tree.persistence(min_persistence=0.001)\n",
    "    \n",
    "    # Plot the barcode diagram\n",
    "    gd.plot_persistence_barcode(persistence=persistent_homology)\n",
    "    plt.show()\n",
    "\n",
    "# Compute the barcode diagrams for each context vector\n",
    "for i, output in enumerate(context):\n",
    "    print(f\"Barcode for text {i}:\")\n",
    "    compute_distances_and_plot_barcode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters for text 0:\n",
      "Cluster 0: E, S\n",
      "Cluster 1: I, P\n",
      "Cluster 2: K, K\n",
      "Cluster 3: F, R, N\n",
      "Cluster 4: T, N\n",
      "Cluster 5: G, R, Q\n",
      "Cluster 6: R, M, V, A\n",
      "Cluster 7: E, E, L, Y, D, K, L, E, A\n",
      "Cluster 8: G, W, M, L\n",
      "Cluster 9: I, S, K, V\n",
      "Cluster 10: E, L, T\n",
      "Cluster 11: R, K\n",
      "Cluster 12: F, A, V, F, T, D, V, R, G, R, K, E, T, M, S, G, R, G, Q, I\n",
      "Cluster 13: F, V, G\n",
      "Cluster 14: T, L, K, Q, I\n",
      "Cluster 15: A, M\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import DBSCAN\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "def cluster_and_get_words(context, sentence, eps):\n",
    "    # Load pre-trained model tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "    # Tokenize input and convert to tensor\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "    # Squeeze the context tensor to remove the batch size dimension\n",
    "    context = context.squeeze(0)\n",
    "\n",
    "    # Compute the pairwise distance matrix\n",
    "    distances = pdist(context.detach().numpy(), 'euclidean')\n",
    "    dist_matrix = squareform(distances)\n",
    "\n",
    "    # Run DBSCAN on the distance matrix\n",
    "    clustering = DBSCAN(eps=eps, min_samples=2, metric='precomputed').fit(dist_matrix)\n",
    "\n",
    "    # Get the words corresponding to each cluster\n",
    "    clusters = {}\n",
    "    for i, label in enumerate(clustering.labels_):\n",
    "        if label != -1:  # Ignore noise (-1 label)\n",
    "            if label not in clusters:\n",
    "                clusters[label] = []\n",
    "            clusters[label].append(tokens[i])\n",
    "\n",
    "    return clusters\n",
    "\n",
    "# Compute the clusters for each context vector\n",
    "clusters = []\n",
    "for i, output in enumerate(context):\n",
    "    print(f\"Clusters for text {i}:\")\n",
    "    clusters.append(cluster_and_get_words(output, text[i], 0.05))\n",
    "    for label, words in clusters[-1].items():\n",
    "        print(f\"Cluster {label}: {', '.join(words)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
